# Translates Jack code into VM commands.

import sys
import os
import re


class JackCompiler:
    # Drives compilation, parsing the input file and emitting VM code to output file, using the JackTokenizer,
    # CompilationEngine, SymbolTable, and VMWriter
    def __init__(self):
        # Argument is either command line argument (if provided) or current working directory (if not). If arg is a
        # .jack file, pass to CompilationEngine. If arg is a directory, for each .jack file in the directory,
        # pass to the file to CompilationEngine.
        if len(sys.argv) == 2:
            arg = sys.argv[1]
        else:
            arg = os.getcwd()

        if arg.endswith('.jack'):
            CompilationEngine(arg)
        else:
            for file in os.listdir(arg):
                if not file.endswith('.jack'):
                    continue

                full_path = os.path.join(arg, file)
                CompilationEngine(full_path)


class JackTokenizer:
    # Tokenizes the input, ignoring comments and whitespace, giving convenient access to each token and its type
    LEXICON = {'keyword': ['class', 'constructor', 'function', 'method', 'field', 'static', 'var', 'int', 'char',
                           'boolean', 'void', 'true', 'false', 'null', 'this', 'let', 'do', 'if', 'else', 'while',
                           'return'],
               'symbol': ['{', '}', '(', ')', '[', ']', '.', ',', ';', '+', '-', '*', '/', '&', '|', '<', '>', '=',
                          '~']
               }

    def __init__(self, arg):
        # Opens the input file and prepares to parse it, removing comments and tokenizing input.
        with open(arg) as self.jack_file:
            data = self.jack_file.read()

        comments_pattern = r'\/\*[\s\S]*?\*\/|\/{2}.*'
        data = re.sub(comments_pattern, '', data)

        tokens_pattern = r'\w+|[{}()\[\].,;+\-*/&|<>=~]|\".*?\"'
        self.tokens = iter(re.findall(tokens_pattern, data))

        self.current_token = next(self.tokens)
        self.next_token = next(self.tokens)

    def has_more_tokens(self):
        # Returns true if there are more tokens.
        if self.current_token is None:
            return False
        return True

    def advance(self):
        # Gets the next token from the input and makes it the current token.
        self.current_token = self.next_token

        try:
            self.next_token = next(self.tokens)
        except StopIteration:
            self.next_token = None

    def token_type(self):
        # Returns the type of the current or next token, as a constant.
        if self.current_token in self.LEXICON['keyword']:
            return 'keyword'
        elif self.current_token in self.LEXICON['symbol']:
            return 'symbol'
        elif self.current_token.isdecimal():
            return 'integerConstant'
        elif self.current_token.startswith('\"'):
            return 'stringConstant'
        else:  # elif self.current_token.isidentifier():
            return 'identifier'

    def next_token_type(self):
        if self.next_token in self.LEXICON['keyword']:
            return 'keyword'
        elif self.next_token in self.LEXICON['symbol']:
            return 'symbol'
        elif self.next_token.isdecimal():
            return 'integerConstant'
        elif self.next_token.startswith('\"'):
            return 'stringConstant'
        else:  # elif self.next_token.isidentifier():
            return 'identifier'

    def get_token(self):
        # Returns the current token.
        if self.token_type() == 'stringConstant':
            return self.current_token[1:-1]
        return self.current_token

    def get_next_token(self):
        # Returns the next token.
        if self.next_token_type() == 'stringConstant':
            return self.next_token()[1:-1]
        return self.next_token


class CompilationEngine:
    # Recursive top-down compilation engine.
    #
    # Gets input from a JackTokenizer and uses a VMWriter for writing VM output. Output is generated by compile_***
    # methods
    CLASS_VAR_DEC = ['static', 'field']

    SUBROUTINE_DEC = ['constructor', 'function', 'method']

    TYPE = ['int', 'char', 'boolean']

    STATEMENT = ['let', 'if', 'while', 'do', 'return']

    OP = {'+': 'add',
          '-': 'sub',
          '*': 'Math.multiply',
          '/': 'Math.divide',
          '&': 'and',
          '|': 'or',
          '<': 'lt',
          '>': 'gt',
          '=': 'eq'
          }

    UNARY_OP = {'-': 'neg',
                '~': 'not'
                }

    KEYWORD_CONSTANT = {'true': ['constant', 1],
                        'false': ['constant', 0],
                        'null': ['constant', 0],
                        'this': ['pointer', 0]
                        }

    def __init__(self, full_path):
        # Creates a new compilation engine.
        #
        # Creates one symbol dictionary (two as specified unneeded.)
        self.tokenizer = JackTokenizer(full_path)
        self.writer = VMWriter(full_path)
        self.symbols = SymbolTable()

        self.class_name = os.path.basename(full_path)[:-5]
        self.subroutine_name = None
        self.subroutine_type = None

        self.if_label_index = 0
        self.while_label_index = 0

        self.compile_class()

        self.writer.close()

    def compile_class(self):
        # Compiles a complete class.
        # class: 'class' className '{' classVarDec* subroutineDec* '}'
        self.tokenizer.advance()

        self.tokenizer.advance()

        self.tokenizer.advance()

        self.compile_class_var_dec()

        self.compile_subroutine()

        self.tokenizer.advance()

    def compile_class_var_dec(self):
        # Compiles a static variable declaration, or a field declaration.
        # classVarDec: ('static'|'field') type varName (',' varName)* ';'
        while self.tokenizer.get_token() in self.CLASS_VAR_DEC:

            kind = self.tokenizer.get_token()
            self.tokenizer.advance()

            type_var = self.tokenizer.get_token()
            self.tokenizer.advance()

            name = self.tokenizer.get_token()
            self.symbols.define(name, type_var, kind)

            self.tokenizer.advance()

            while self.tokenizer.get_token() == ',':
                self.tokenizer.advance()

                name = self.tokenizer.get_token()
                self.symbols.define(name, type_var, kind)

                self.tokenizer.advance()

            self.tokenizer.advance()

    def compile_subroutine(self):
        # Compiles a complete method, function, or constructor.
        # subroutineDec: ('constructor'|'function'|'method') ('void' | type) subroutineName '(' parameterList ')'
        # subroutineBody
        while self.tokenizer.get_token() in self.SUBROUTINE_DEC:

            self.subroutine_type = self.tokenizer.get_token()

            if self.subroutine_type == 'method':
                self.symbols.define('this', self.class_name, 'arg')

            self.tokenizer.advance()

            self.tokenizer.advance()

            self.subroutine_name = self.tokenizer.get_token()
            self.tokenizer.advance()

            self.tokenizer.advance()
            self.compile_parameter_list()
            self.tokenizer.advance()

            self.compile_subroutine_body()

            self.symbols.reset_subroutine_symbols()

    def compile_parameter_list(self):
        # Compiles a (possibly empty) parameter list. Does not handle the enclosing parentheses tokens '(' and ')'.
        # parameterList: ((type varName) (',' type varName)*)?
        if self.tokenizer.get_token() in self.TYPE or self.tokenizer.token_type() == 'identifier':
            type_var = self.tokenizer.get_token()
            self.tokenizer.advance()

            name = self.tokenizer.get_token()
            self.tokenizer.advance()

            self.symbols.define(name, type_var, 'arg')

            while self.tokenizer.get_token() == ',':
                self.tokenizer.advance()

                type_var = self.tokenizer.get_token()
                self.tokenizer.advance()

                name = self.tokenizer.get_token()
                self.tokenizer.advance()

                self.symbols.define(name, type_var, 'arg')

    def compile_subroutine_body(self):
        # Compiles the body of a subroutine.
        # subroutineBody: '{' varDec* statements '}'
        self.tokenizer.advance()
        self.compile_var_dec()

        function_name = f'{self.class_name}.{self.subroutine_name}'
        n_vars = self.symbols.var_count('var')  # n_vars is number of local variables in subroutine
        self.writer.write_function(function_name, n_vars)

        if self.subroutine_type == 'method':
            self.writer.write_push('argument', 0)
            self.writer.write_pop('pointer', 0)

        elif self.subroutine_type == 'constructor':
            n_fields = self.symbols.var_count('field')  # n_fields is number of fields in class
            self.writer.write_push('constant', n_fields)
            self.writer.write_call('Memory.alloc', 1)
            self.writer.write_pop('pointer', 0)

        self.compile_statements()
        self.tokenizer.advance()

    def compile_var_dec(self):
        # Compiles a var declaration.
        # varDec: 'var' type varName (',' varName)* ';'
        while self.tokenizer.get_token() == 'var':
            self.tokenizer.advance()

            type_var = self.tokenizer.get_token()
            self.tokenizer.advance()

            name = self.tokenizer.get_token()
            self.tokenizer.advance()

            self.symbols.define(name, type_var, 'var')

            while self.tokenizer.get_token() == ',':
                self.tokenizer.advance()

                name = self.tokenizer.get_token()
                self.tokenizer.advance()

                self.symbols.define(name, type_var, 'var')

            self.tokenizer.advance()

    def compile_statements(self):
        # Compiles a sequence of statements. Does not handle the enclosing curly bracket tokens '{' and '}'.
        # statements: statement*
        # statement: letStatement | ifStatement | whileStatement | doStatement | returnStatement
        while self.tokenizer.get_token() in self.STATEMENT:
            if self.tokenizer.get_token() == 'let':
                self.compile_let()

            elif self.tokenizer.get_token() == 'if':
                self.compile_if()

            elif self.tokenizer.get_token() == 'while':
                self.compile_while()

            elif self.tokenizer.get_token() == 'do':
                self.compile_do()

            else:  # if self.tokenizer.token() == "return":
                self.compile_return()

    def compile_let(self):
        # Compiles a let statement.
        # letStatement: 'let' varName ('[' expression ']')? '=' expression ';'
        self.tokenizer.advance()

        var_name = self.tokenizer.get_token()
        self.tokenizer.advance()

        if self.tokenizer.get_token() == '=':  # varName = expression;
            self.tokenizer.advance()

            self.compile_expression()

            self.tokenizer.advance()

            self.writer.write_pop(self.symbols.kind(var_name), self.symbols.index(var_name))

        else:  # elif self.tokenizer.get_token() == '[':  # varName[expression] = expression;
            self.writer.write_push(self.symbols.kind(var_name), self.symbols.index(var_name))

            self.tokenizer.advance()
            self.compile_expression()
            self.tokenizer.advance()

            self.writer.write_arithmetic('add')

            self.tokenizer.advance()

            self.compile_expression()

            self.tokenizer.advance()

            self.writer.write_pop('temp', 0)
            self.writer.write_pop('pointer', 1)
            self.writer.write_push('temp', 0)
            self.writer.write_pop('that', 0)

    def compile_if(self):
        # Compiles an if statement, possibly with a trailing else clause.
        # ifStatement: 'if' '(' expression ')' '{' statements '}' ('else' '{' statements '}')?
        self.tokenizer.advance()

        self.tokenizer.advance()
        self.compile_expression()
        self.tokenizer.advance()

        self.writer.write_arithmetic('not')

        if_false = 'IF_FALSE' + str(self.if_label_index)
        if_end = 'IF_END' + str(self.if_label_index)
        self.if_label_index += 1

        self.writer.write_if(if_false)

        self.tokenizer.advance()
        self.compile_statements()
        self.tokenizer.advance()

        self.writer.write_goto(if_end)

        self.writer.write_label(if_false)

        if self.tokenizer.get_token() == 'else':
            self.tokenizer.advance()

            self.tokenizer.advance()
            self.compile_statements()
            self.tokenizer.advance()

        self.writer.write_label(if_end)

    def compile_while(self):
        # Compiles a while statement.
        # whileStatement: 'while' '(' expression ')' '{' statements '}'
        self.tokenizer.advance()

        while_exp = 'WHILE_EXP' + str(self.while_label_index)
        while_end = 'WHILE_END' + str(self.while_label_index)
        self.while_label_index += 1

        self.writer.write_label(while_exp)

        self.tokenizer.advance()
        self.compile_expression()
        self.tokenizer.advance()

        self.writer.write_arithmetic('not')

        self.writer.write_if(while_end)

        self.tokenizer.advance()
        self.compile_statements()
        self.tokenizer.advance()

        self.writer.write_goto(while_exp)

        self.writer.write_label(while_end)

    def compile_do(self):
        # Compiles a do statement.
        # doStatement: 'do' subroutineCall ';'
        self.tokenizer.advance()

        self.compile_subroutine_call()

        self.writer.write_pop('temp', 0)

        self.tokenizer.advance()

    def compile_return(self):
        # Compiles a return statement.
        # returnStatement 'return' expression? ';'
        self.tokenizer.advance()

        if self.is_expression():
            self.compile_expression()
        else:  # if void method or function
            self.writer.write_push('constant', 0)

        self.writer.write_return()

        self.tokenizer.advance()

    def compile_expression(self):
        # Compiles an expression.
        # expression: term (op term)*
        self.compile_term()

        while self.tokenizer.get_token() in self.OP:
            if self.tokenizer.get_token() in ['*', '/']:
                name = self.OP[self.tokenizer.get_token()]
                self.tokenizer.advance()

                self.compile_term()

                self.writer.write_call(name, 2)
            else:
                command = self.OP[self.tokenizer.get_token()]
                self.tokenizer.advance()

                self.compile_term()

                self.writer.write_arithmetic(command)

    def compile_term(self):
        # Compiles a term. If the current token is an identifier, the method must resolve it into a variable,
        # an array element, or a subroutine call.
        # term: integerConstant | stringConstant | keywordConstant | varName | varName '[' expression '] |
        # '(' expression ')' | (unaryOp term) | subroutineCall

        # integerConstant
        if self.tokenizer.token_type() == 'integerConstant':
            self.writer.write_push('constant', self.tokenizer.current_token)
            self.tokenizer.advance()

        # stringConstant
        elif self.tokenizer.token_type() == 'stringConstant':
            string = self.tokenizer.get_token()

            self.writer.write_push('constant', len(string))

            self.writer.write_call('String.new', 1)

            for char in string:
                self.writer.write_push('constant', ord(char))

                self.writer.write_call('String.appendChar', 2)

            self.tokenizer.advance()

        # keywordConstant
        elif self.tokenizer.get_token() in self.KEYWORD_CONSTANT:
            segment = self.KEYWORD_CONSTANT[self.tokenizer.get_token()][0]
            index = self.KEYWORD_CONSTANT[self.tokenizer.get_token()][1]
            self.writer.write_push(segment, index)

            if self.tokenizer.get_token() == 'true':
                self.writer.write_arithmetic('neg')

            self.tokenizer.advance()

        elif self.tokenizer.token_type() == 'identifier':

            # varName '[' expression '] -> array
            if self.tokenizer.get_next_token() == '[':
                var_name = self.tokenizer.get_token()
                self.tokenizer.advance()

                var_kind = self.symbols.kind(var_name)
                var_index = self.symbols.index(var_name)
                self.writer.write_push(var_kind, var_index)

                self.tokenizer.advance()
                self.compile_expression()
                self.tokenizer.advance()

                self.writer.write_arithmetic('add')
                self.writer.write_pop('pointer', 1)
                self.writer.write_push('that', 0)

            # subroutineCall
            elif self.tokenizer.get_next_token() in ['(', '.']:
                self.compile_subroutine_call()

            # varName (not array or subroutineCall)
            else:
                var_name = self.tokenizer.get_token()
                self.tokenizer.advance()

                var_kind = self.symbols.kind(var_name)
                var_index = self.symbols.index(var_name)
                self.writer.write_push(var_kind, var_index)

        # '(' expression ')'
        elif self.tokenizer.get_token() == '(':
            self.tokenizer.advance()
            self.compile_expression()
            self.tokenizer.advance()

        # unaryOp term
        elif self.tokenizer.get_token() in self.UNARY_OP:
            op = self.UNARY_OP[self.tokenizer.get_token()]
            self.tokenizer.advance()

            self.compile_term()

            self.writer.write_arithmetic(op)

    def compile_expression_list(self):
        # Compiles a (possibly empty) comma-separated list of expressions. Returns the number of expressions in the
        # list.
        # expressionList: (expression (',' expression)* )?
        count = 0

        # if expression -> if term ...
        if self.is_expression():
            self.compile_expression()
            count += 1

            while self.tokenizer.get_token() == ',':
                self.tokenizer.advance()

                self.compile_expression()
                count += 1

        return count

    def compile_subroutine_call(self):
        # Compiles a subroutineCall.
        # subroutineCall: subroutineName '(' expressionList ')' | (className | varName) '.' subroutineName
        # '(' expressionList ')'
        if self.tokenizer.get_next_token() == '.':

            # className.subroutineName(expressionList)
            if self.tokenizer.get_token()[0].isupper():
                class_name = self.tokenizer.get_token()
                self.tokenizer.advance()

                self.tokenizer.advance()

                subroutine_name = self.tokenizer.get_token()
                self.tokenizer.advance()

                self.tokenizer.advance()
                n_args = self.compile_expression_list()
                self.tokenizer.advance()

                name = f'{class_name}.{subroutine_name}'

            # varName.subroutineName(expressionList)
            else:
                var_name = self.tokenizer.get_token()
                self.tokenizer.advance()

                var_type = self.symbols.type(var_name)  # className is type of varName
                var_kind = self.symbols.kind(var_name)
                index = self.symbols.index(var_name)
                self.writer.write_push(var_kind, index)

                self.tokenizer.advance()

                subroutine_name = self.tokenizer.get_token()
                self.tokenizer.advance()

                self.tokenizer.advance()
                n_args = self.compile_expression_list() + 1
                self.tokenizer.advance()

                name = f'{var_type}.{subroutine_name}'

        # subroutineName(expressionList) -> this.subroutineName(expressionList)
        else:
            self.writer.write_push('pointer', 0)

            subroutine_name = self.tokenizer.get_token()
            self.tokenizer.advance()

            self.tokenizer.advance()
            n_args = self.compile_expression_list() + 1
            self.tokenizer.advance()

            name = f'{self.class_name}.{subroutine_name}'

        self.writer.write_call(name, n_args)

    def is_expression(self):
        # Returns true if the current token indicates an expression -> term, else false.
        if self.tokenizer.token_type() in ['integerConstant', 'stringConstant', 'identifier'] \
                or self.tokenizer.get_token() == '(' or self.tokenizer.get_token() in self.KEYWORD_CONSTANT \
                or self.tokenizer.get_token() in self.UNARY_OP:
            return True
        return False


class SymbolTable:
    # Builds, populates, and uses symbol dictionary that records the symbol properties name, type, kind, and index for
    # each kind.
    SEGMENTS = {'static': 'static',
                'field': 'this',
                'arg': 'argument',
                'var': 'local'
                }

    def __init__(self):
        # Creates a new symbol dictionary and initialize kind index
        self.symbols = {}
        self.indexes = {'static': 0,
                        'field': 0,
                        'arg': 0,
                        'var': 0
                        }

    def reset_subroutine_symbols(self):
        # Resets the symbols within the subroutine scope by removing symbols whose kind is arg or var and resetting
        # the index of kind arg and var
        new_symbols = {}
        for symbol, value in self.symbols.items():
            if value[1] in ['arg', 'var']:
                continue
            new_symbols[symbol] = value
        self.symbols = new_symbols

        self.indexes['arg'], self.indexes['var'] = 0, 0

    def define(self, name, type_var, kind):
        # Adds a new variable of the given name, type, and kind, and increments the proper index.
        self.symbols[name] = [type_var, kind, self.indexes[kind]]
        self.indexes[kind] += 1

    def var_count(self, kind):
        # Returns the number of variables of the given kind already defined in the dictionary.
        return self.indexes[kind]

    def kind(self, name):
        # Returns the kind of the named identifier. If not found, returns None.
        if name not in self.symbols:
            return None
        return self.SEGMENTS[self.symbols[name][1]]

    def type(self, name):
        # Returns the type of the named identifier.
        return self.symbols[name][0]

    def index(self, name):
        # Returns the index of the named identifier.
        return self.symbols[name][2]


class VMWriter:
    # Writes VM commands to the output file.
    def __init__(self, full_path):
        # Creates a new .vm output file and prepares to write to it.
        filename = full_path[:-4] + 'vm'
        self.vm_file = open(filename, 'w')

    def write_push(self, segment, index):
        # Writes a VM push command.
        self.vm_file.write(f'push {segment} {index}\n')

    def write_pop(self, segment, index):
        # Writes a VM pop command.
        self.vm_file.write(f'pop {segment} {index}\n')

    def write_arithmetic(self, command):
        # Writes a VM arithmetic-logical command.
        self.vm_file.write(f'{command}\n')

    def write_label(self, label):
        # Writes a VM label command.
        self.vm_file.write(f'label {label}\n')

    def write_goto(self, label):
        # Writes a VM goto command.
        self.vm_file.write(f'goto {label}\n')

    def write_if(self, label):
        # Writes a VM if-goto command.
        self.vm_file.write(f'if-goto {label}\n')

    def write_call(self, name, n_args):
        # Writes a VM call command.
        self.vm_file.write(f'call {name} {n_args}\n')

    def write_function(self, name, n_vars):
        # Writes a VM function command.
        self.vm_file.write(f'function {name} {n_vars}\n')

    def write_return(self):
        # Writes a VM return command.
        self.vm_file.write('return\n')

    def close(self):
        # Closes the output file.
        self.vm_file.close()


JackCompiler()
